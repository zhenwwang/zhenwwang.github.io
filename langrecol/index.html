
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>LangRecol</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <meta property="og:image" content="https://jonbarron.info/zipnerf/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" /> -->
    <!-- <meta property="og:url" content="https://zhenwwang.github.io/langrecol"/>
    <meta property="og:title" content="Language-based Photo Color Adjustment for Graphic Designs" />
    <meta property="og:description" content="We present LangRecol, a new language-based approach for recoloring photos in graphic designs. LangRecol uses deep networks to predict user-specified source colors and target objects/regions and then recolors the photo via a semantic-palette-based photo recoloring module. Extensive experiments and several applications demonstrate the effectiveness and practicality of our approach." /> -->

    <!-- <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields" />
    <meta name="twitter:description" content="Neural Radiance Field training can be accelerated through the use of grid-based representations in NeRF's learned mapping from spatial coordinates to colors and volumetric density. However, these grid-based approaches lack an explicit understanding of scale and therefore often introduce aliasing, usually in the form of jaggies or missing scene content. Anti-aliasing has previously been addressed by mip-NeRF 360, which reasons about sub-volumes along a cone rather than points along a ray, but this approach is not natively compatible with current grid-based techniques. We show how ideas from rendering and signal processing can be used to construct a technique that combines mip-NeRF 360 and grid-based models such as Instant NGP to yield error rates that are 8%-76% lower than either prior technique, and that trains 22x faster than mip-NeRF 360." />
    <meta name="twitter:image" content="https://jonbarron.info/zipnerf/img/teaser.jpg" /> -->


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Language-based Photo Color Adjustment for Graphic Designs</br> 
                <small>
                    <em>ACM Trans. on Graphics (Proc. ACM SIGGRAPH 2023)</em>, August 2023
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://zhenwwang.github.io">
                          Zhenwei Wang <sup>1*</sup>
                        </a>
                    </li>
                    <li>
                        <a href="http://nxzhao.com/">Nanxuan Zhao <sup>2*</sup> </a>,
                    </li>
                    <li>
                        <a href="http://rfidblog.org.uk/">Gerhard Hancke <sup>1</sup></a>
                    </li>
                    <li>
                        <a href="https://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau <sup>1&dagger;</sup></a>
                    </li>
                    </br><sup>1</sup>: City University of Hong Kong, Hong Kong SAR, China &nbsp &nbsp <sup>2</sup>: Adobe Research, California, USA
                    </br><sup>*</sup>: Both authors contributed equally to this research &nbsp &nbsp <sup>&dagger;</sup>: Corresponding author
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://zhenwwang.github.io/langrecol/files/LangRecol_SIGGRAPH23_Wang.pdf">
                            <image src="img/paper.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://zhenwwang.github.io/langrecol/files/Sup_LangRecol_SIGGRAPH23_Wang.pdf">
                            <image src="img/paperclip.png" height="60px">
                                <h4><strong>Supplementary material</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://youtu.be/AGHhK4XRwqk?si=Hd52rPwGEOaJyiFP">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://zhenwwang.github.io/langrecol">
                            <image src="img/github_pad.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <img src="img/teaser.jpg" style="margin:auto;max-width:100%" align="middle">
				</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Adjusting the photo color to associate with some design elements is an essential way for a graphic design to effectively deliver its message and make it aesthetically pleasing. However, existing tools and previous works face a dilemma between the ease of use and level of expressiveness. To this end, we introduce an interactive language-based approach for photo recoloring, which provides an intuitive system that can assist both experts and novices on graphic design. Given a graphic design containing a photo that needs to be recolored, our model can predict the source colors and the target regions, and then recolor the target regions with the source colors based on the given language-based instruction. The multi-granularity of the instruction allows diverse user intentions. The proposed novel task faces several unique challenges, including: 1) <b>color accuracy</b> for recoloring with exactly the same color from the target design element as specified by the user; 2) <b>multi-granularity instructions</b> for parsing instructions correctly to generate a specific result or multiple plausible ones; and 3) <b>locality</b> for recoloring in semantically meaningful local regions to preserve original image semantics. To address these challenges, we propose a model called LangRecol with two main components: the language-based source color prediction module and the semantic-palette-based photo recoloring module. We also introduce an approach for generating a synthetic graphic design dataset with instructions to enable model training. We evaluate our model via extensive experiments and user studies. We also discuss several practical applications, showing the effectiveness and practicality of our approach.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>
                <img src="img/pipeline_overview.png" style="margin:auto;max-width:100%" align="middle">
                <br/>
                <br/>
                <p class="text-justify">
                    <b>Overview of our pipeline.</b> There are two key components in our pipeline: (1) <b>language-based source color prediction</b> aims to predict the source colors from the user-specified design elements (i.e., “title”); (2) <b>semantic-palette-based photo recoloring</b> aims to recolor the user-specified local regions (i.e., “blue sofa”) in the photo with the predicted source colors.
                </p>
				</div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <img src="img/recolored_results.png" style="margin:auto;max-width:100%" align="middle">
                <br/>
                <br/>
                <p class="text-justify">
                    <b>Our language-based photo recoloring results on graphic designs.</b> For each design case, we show the original design on the left and our result(s) on the right, with the predicted source color and the input instruction below. We highlight the words related to the source colors and target regions in bold.
                </p>
                <img src="img/qualitative_overall_results.png" style="margin:auto;max-width:100%" align="middle">
                <br/>
                <br/>
                <p class="text-justify">
                    <b>Comparison results with state-of-the-art methods.</b> We compare with two language-based image recoloring methods: Open-edit  [Liu et al. 2020] and ManiGAN [Li et al. 2020b]; and a graphic design photo recoloring method GDRecolor [Zhao et al. 2021].
                </p>
				</div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Applications
                </h3>
                <h4>
                    1. Design template pairing
                </h4>
                <img src="img/application_1_S.png" style="margin:auto;max-width:100%" align="middle">
                <p class="text-justify">
                    <b>Design template pairing.</b> Our model can adjust photo color based on a set of design templates for quick brainstorm and authoring.
                </p>
                <h4>
                    2. Brochure Photo Recoloring
                </h4>
                <img src="img/application_2_S.png" style="margin:auto;max-width:100%" align="middle">
                <p class="text-justify">
                    <b>Brochure Photo Recoloring.</b> Our model can recolor multiple photos with a single design.
                </p>
                <h4>
                    3. Recoloring a design collection
                </h4>
                <img src="img/application_3_S.png" style="margin:auto;max-width:100%" align="middle">
                <p class="text-justify">
                    <b>Recoloring a design collection.</b> We show a design case for banners used in online promotion.
                </p>
                <h4>
                    4. Iterative graphic design photo recoloring
                </h4>
                <img src="img/application_4_S.png" style="margin:auto;max-width:100%" align="middle">
				</div>
        </div>

<!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://youtube.com/embed/xrrhynRzC8k" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-20 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" readonly>
@article{10.1145/3592111,
    author = {Wang, Zhenwei and Zhao, Nanxuan and Hancke, Gerhard and Lau, Rynson W.H.},
    title = {Language-Based Photo Color Adjustment for Graphic Designs},
    year = {2023},
    issue_date = {August 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {42},
    number = {4},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/3592111},
    doi = {10.1145/3592111},
    journal = {ACM Trans. Graph.},
    month = {jul},
    articleno = {101},
    numpages = {16},
    keywords = {language-guided, data-driven graphic design, photo recoloring}
    }
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    We thank the anonymous reviewers for the insightful comments and constructive suggestions on our paper. This work is in part supported by a GRF grant from the Research Grants Council of Hong Kong (Ref. No.: 11205620).
                </p>
            </div>
        </div>
    </div>
</body>
</html>
